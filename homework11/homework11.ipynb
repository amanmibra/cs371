{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "homework11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yBin6pi72nft",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "# COMPSCI 371D Homework 11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gYQdebYN2nfu",
        "tags": [
          "T"
        ]
      },
      "source": [
        "Write the names of all contributors to this assignment here:\n",
        "\n",
        "+ ...\n",
        "+ ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aymIv7MFIbwz",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "## Homework Submission Workflow\n",
        "\n",
        "When you submit your work, follow the instructions on the [submission workflow page](https://www.cs.duke.edu/courses/fall19/compsci371d/homework/workflow.html) for full credit, but see the changes mentioned below.\n",
        "\n",
        "<span style=\"color:red\">**Important changes to homework preparation workflow:** _**This assignment is different from the others in that you are required to run it on the Google Colaboratory, a cloud service that Google makes available for reseach in machine learning.**_ </span>\n",
        "\n",
        "This is necessary because one of the problems requires you to train a deep network on hardware that is faster than what is typically available on a standard laptop or desktop, including a high-end GPU. Even if you do have a high-end GPU, please run your notebook on the Colaboratory, so we can grade your work consistently. \n",
        "\n",
        "_**To work on this assignment, go to the [Colaboratory](https://colab.research.google.com) and upload the template notebook for this assignment through the `File` menu at the top of the Colaboratory page. Then work on the assignment.**_\n",
        "\n",
        "_**When you are done, download the notebook (after making sure that all the outputs from running the code show up properly), and proceed as usual to turn that notebook into a PDF file for submission.**_\n",
        "\n",
        "#### Programming Notes\n",
        "\n",
        "+ Before you run any of your code cells, go to the `Runtime->Change runtime type` menu and make sure that the hardware acceleration is set to `GPU`. This is very important: With acceleration set to `None`, your code would run on the CPU and take forever.\n",
        "+ The Colaboratory is a cloud service. If a notebook sits idle for a long time, it automatically disconnects from its execution kernel, and you need to rerun all the cells.\n",
        "+ Once you are done with the assignment, the safest thing to do is to do `Runtime->Reset all runtimes`, and `Runtime->Run all` to run all cells. Check all your output after that.\n",
        "+ Training depends on random initialization of the network parameters. Because of this, your results may vary relative to the sample solution, even if your code is no different. Results may also vary from run to run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gIp6dzlwIbw0",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "## Part 1: Exam-Style Questions, Set 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6o90sGDiK4aF",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "The small neural net in the figure below uses the ReLU as the nonlinearity at the output of each neuron. The values specified in the hollow circles are biases, and the values along the edges are gains. Weigths number 1, 2, 3 refer to the first neuron, 4, 5,6 to the second, 7, 8, 9 to the third."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CakDYmy0Mk13",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "![a simple neural network](https://www2.cs.duke.edu/courses/spring19/compsci527/homework/5/netSimple.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tdrtWLQ5JZ7q",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "### Problem 1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CacoODWaJdmL",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "Are all the layers in the net above fully connected?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WJ9w1-GpN1FM",
        "tags": [
          "ST"
        ]
      },
      "source": [
        "### Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4o_0Co16OJ-v",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "### Problem 1.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WmVrDJydN7OP",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "What is the output $y$ from the net above when the input is as follows?\n",
        "\n",
        "$$\n",
        "x_1 = 0 \\;\\;\\; \\text{and}\\;\\;\\; x_2 = 3\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G-LZGjFMORa8",
        "tags": [
          "ST"
        ]
      },
      "source": [
        "### Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rP4qW1wUQapl",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "### Problem 1.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2WZXG8wNQeJ5",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "What is the gradient $\\mathbf{g}$ of the output $y$ of the network above with respect to the weight vector\n",
        "\n",
        "$$\n",
        "\\mathbf{w} = [w_1,\\ w_2,\\ w_3,\\ w_4,\\ w_5,\\ w_6,\\ w_7,\\ w_8,\\ w_9]^T\n",
        "$$\n",
        "\n",
        "when the input has the values given in the previous problem? Just give the result if you are confident of your answer.\n",
        "\n",
        "**Hint:** Compute all activations in a forward pass throught the network. Then let $g_k = \\partial y/\\partial w_k$ for notational simplicity, and compute these gradients backwards: $g_7, g_8, g_9$, then $g_1, g_2, g_3$, then $g_4, g_5, g_6$. Finally, collect all the $g_k$ into a vector $\\mathbf{g}$ in order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5fVXbN93RDq7",
        "tags": [
          "ST"
        ]
      },
      "source": [
        "### Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j_-dO56ledsy",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "\n",
        "## Part 2: Exam-Style Questions, Set 2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CWV3624YZjhu",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "Let $\\mathbf{p} = f(\\mathbf{x})$ be the output of the final, soft-max layer of some neural network classifier with $K$ layers when the network's input is $\\mathbf{x}$. The classifier's output is then\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\arg\\max \\mathbf{p}\\;.\n",
        "$$\n",
        "\n",
        "If $y_n$ is the true label corresponding to training input $\\mathbf{x}_n$, the loss is $\\ell_n = \\ell(y_n, f(\\mathbf{x}_n))$ for some loss function $\\ell(y, \\mathbf{p})$ appropriate for the task.\n",
        "\n",
        "We saw in class that if $\\mathbf{x}^{(k)}$ is the output from layer $k$ and $\\mathbf{w}^{(k)}$ is a vector with all the parameters in layer $k$, then back-propagation computes the partial derivatives by the following recursion,  where $\\mathbf{x}^{(0)} = \\mathbf{x}$ is the input to the network and $\\mathbf{x}^{(K)} = \\mathbf{p}$:\n",
        "\n",
        "\\begin{eqnarray*}\n",
        "\\frac{\\partial \\ell_n}{\\partial \\mathbf{w}^{(k)}} &=& \\frac{\\partial \\ell_n}{\\partial \\mathbf{x}^{(k)}} \\frac{\\partial \\mathbf{x}^{(k)}}{\\partial \\mathbf{w}^{(k)}}\n",
        "\\;\\;\\;\\text{for}\\;\\;\\; k = K,\\ldots, 1 \\\\\n",
        "\\frac{\\partial \\ell_n}{\\partial \\mathbf{x}^{(k-1)}} &=& \\frac{\\partial \\ell_n}{\\partial \\mathbf{x}^{(k)}} \\frac{\\partial \\mathbf{x}^{(k)}}{\\partial \\mathbf{x}^{(k-1)}}\n",
        "\\;\\;\\;\\text{for}\\;\\;\\; k = K,\\ldots, 2\\\\\n",
        "\\frac{\\partial \\ell_n}{\\partial \\mathbf{x}^{(K)}} &=& \\frac{\\partial \\ell}{\\partial \\mathbf{p}}\n",
        "\\end{eqnarray*}\n",
        "\n",
        "The derivatives above are computed for the $n$-th training sample $(\\mathbf{x}_n, y_n)$ and for the values of $\\mathbf{w}^{(k)}$ that are current at any given point during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cNK7pnfDesaH",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "### Problem 2.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vY-vJZ_Peu9c",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "Suppose that the network has only fully-connected layers (with ReLU nonlinearities) before the soft-max. Refer in detail to the equations given above to explain clearly why training would not work if the parameter vector $\\mathbf{w} = [\\mathbf{w}^{(1)},\\ldots, \\mathbf{w}^{(K)}]^T$ is initialized with zeros for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I5CVu5NXhUpK",
        "tags": [
          "ST"
        ]
      },
      "source": [
        "### Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Vx-msEHjfdn",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "### Problem 2.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NJnaTzLfjiGt",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "A neural net classifier with only fully-connected layers (with ReLU nonlinearities) and a soft-max layer at its output has parameter vector $\\mathbf{w}$, and the network  implements the function $f(\\mathbf{x}, \\mathbf{w})$ for any network input $\\mathbf{x}$. Is $\\mathbf{w} = \\mathbf{0}$ a stationary point for the function $\\phi(\\mathbf{w}) = f(\\mathbf{x}, \\mathbf{w})$ when $\\mathbf{x}$ is fixed? Justify your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OxjAkNkzkDHo",
        "tags": [
          "ST"
        ]
      },
      "source": [
        "### Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rla5OsKGk1zi",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "### Problem 2.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lE3Uoh6Hk5jp",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "Stochastic gradient descent with momentum is used to train a certain neural network with $m$ parameters. Just before iteration $t$ of training is performed, the parameter vector has value $\\mathbf{w}_t$, and the velocity (or step) is $\\mathbf{v}_t = \\mathbf{a}$, where $\\mathbf{a}$ is some nonzero vector in $\\mathbb{R}^m$ (refer to the class notes for notation). The momentum coefficient is kept constant at $\\mu = 0.9$ throughout training. If the risk function has a saddle point at $\\mathbf{w}_t$, what is the step $\\mathbf{v}_{t+1}$ at iteration $t$, in terms of $\\mathbf{a}$ and any relevant parameters?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qTU6DAPRn1hN",
        "tags": [
          "ST"
        ]
      },
      "source": [
        "### Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lfRyRIt3qCoz",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "### Problem 2.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RWfz9zLXqFAV",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "In the situation described in Problem 2.3, will the training algorithm always eventually converge back towards $\\mathbf{w}_t$? Explain your answer briefly and clearly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zv-spO4mqZcT",
        "tags": [
          "ST"
        ]
      },
      "source": [
        "### Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8GZdQ7IsoUVR",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "## Part 3: Experiment with CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4gQIvWQAzhzm",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "The code in this part is somewhat modified from [a blog on Keras](https://adventuresinmachinelearning.com/keras-eager-and-tensorflow-2-0-a-new-tf-paradigm/). It downloads the CIFAR-10 dataset, a set of 60000 labeled images grouped in 10 categories, which it splits into training and validation sets. The code also prints the sizes of these two sets.\n",
        "\n",
        "For both training and validation data, the image pixel values are normalized to [0, 1] by dividing them by 255, and the labels are converted to one-hot encoding. Training images are also flipped left-to-right at random, to provide a simple form of data augmentation. Images are provided in random order to the training algorithm in batches of 32 samples.\n",
        "\n",
        "The code then defines a function `SimpleNetwork` that returns a simple convolutional neural network (the `model`), and a function `train` that reinitializes the model and trains it for the specified number of epochs (an epoch is a full run through the data set) and descent steps per epoch, using the specified optimizer. The default optimizer is ADAM, a variant of stochastic gradient descent that selects the descent step adaptively. We will use this optimizer in this Part.\n",
        "\n",
        "Finally, the code instantiates the model.\n",
        "\n",
        "_**Important:**_ Make sure you select Python 3 through the `Runtime->Change runtime type` menu at the top of the notebook. Also set the hardware acceleration to `GPU` in that same menu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GUVXxogoJGls",
        "tags": [
          "AST"
        ],
        "colab": {}
      },
      "source": [
        "% tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import datetime as dt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VK1OmNElJdoV",
        "tags": [
          "AST"
        ],
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_validate, y_validate) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32).shuffle(10000)\n",
        "train_dataset = train_dataset.map(lambda x, y: (tf.math.divide(tf.cast(x, tf.float32), 255.0),\n",
        "                                                tf.reshape(tf.one_hot(y, 10), (-1, 10))))\n",
        "train_dataset = train_dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
        "train_dataset = train_dataset.repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R4dgE9sGKFZw",
        "tags": [
          "AST"
        ],
        "colab": {}
      },
      "source": [
        "valid_dataset = tf.data.Dataset.from_tensor_slices((x_validate, y_validate)).batch(len(y_validate))\n",
        "valid_dataset = valid_dataset.map(lambda x, y: (tf.math.divide(tf.cast(x, tf.float32), 255.0),\n",
        "                                                tf.reshape(tf.one_hot(y, 10), (-1, 10))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jc1sId-fBErO",
        "tags": [
          "AST"
        ],
        "colab": {}
      },
      "source": [
        "print('{} training and {} validation samples'.format(len(y_train), len(y_validate)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y_0LSCpbKLHv",
        "tags": [
          "AST"
        ],
        "colab": {}
      },
      "source": [
        "class SimpleNetwork(keras.Model):\n",
        "    def __init__(self):\n",
        "        super(SimpleNetwork, self).__init__(name='cifar_cnn')\n",
        "        self.conv1 = keras.layers.Conv2D(64, 5,\n",
        "                                         padding='same',\n",
        "                                         activation=tf.nn.relu,\n",
        "                                         kernel_initializer=tf.initializers.VarianceScaling,\n",
        "                                         kernel_regularizer=keras.regularizers.l2(l=0.001))\n",
        "        self.max_pool2d = keras.layers.MaxPooling2D((3, 3), (2, 2), padding='same')\n",
        "        self.max_norm = keras.layers.BatchNormalization()\n",
        "        self.conv2 = keras.layers.Conv2D(64, 5,\n",
        "                                         padding='same',\n",
        "                                         activation=tf.nn.relu,\n",
        "                                         kernel_initializer=tf.initializers.VarianceScaling,\n",
        "                                         kernel_regularizer=keras.regularizers.l2(l=0.001))\n",
        "        self.flatten = keras.layers.Flatten()\n",
        "        self.fc1 = keras.layers.Dense(750, activation=tf.nn.relu,\n",
        "                                      kernel_initializer=tf.initializers.VarianceScaling,\n",
        "                                      kernel_regularizer=keras.regularizers.l2(l=0.001))\n",
        "        self.dropout = keras.layers.Dropout(0.5)\n",
        "        self.fc2 = keras.layers.Dense(10)\n",
        "        self.softmax = keras.layers.Softmax()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.max_pool2d(self.conv1(x))\n",
        "        x = self.max_norm(x)\n",
        "        x = self.max_pool2d(self.conv2(x))\n",
        "        x = self.max_norm(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return self.softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zZFZFYCMKSbJ",
        "tags": [
          "AST"
        ],
        "colab": {}
      },
      "source": [
        "class ProgressReport(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def __init__(self, epochs):\n",
        "    print('{} epochs:'.format(epochs), end=' ')\n",
        "\n",
        "  def on_epoch_begin(self, epoch, logs=None):\n",
        "    pass\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    print(epoch, end=' ')\n",
        "    if epoch > 0 and epoch % 20 == 0:\n",
        "      print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JqP6uy6HPXaN",
        "tags": [
          "AST"
        ],
        "colab": {}
      },
      "source": [
        "def train(model, epochs=100, steps_per_epoch=1000, optimizer=tf.optimizers.Adam()):\n",
        "  now = dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "  progress = ProgressReport(epochs)\n",
        "  callbacks = [\n",
        "    keras.callbacks.History(),\n",
        "    progress\n",
        "  ]\n",
        "\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  history = model.fit(train_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
        "                      validation_data=valid_dataset, validation_steps=1,\n",
        "                      callbacks=callbacks, verbose=0)\n",
        "  return history\n",
        "\n",
        "model = SimpleNetwork()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KEp7_h36bC7R",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "### Problem 3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UxdkfA9ibFUM",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "Train the `model` with the call\n",
        "\n",
        "    history = train(model)\n",
        "\n",
        "Training will take several minutes.\n",
        "\n",
        "When done, use the function `plot_performance` below with argument `history` to display plots of training and validation risk and accuracy as a function of training epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QmJSBRnHq_Qh",
        "tags": [
          "AST"
        ],
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_performance(h):\n",
        "  plt.figure(figsize=(15, 5))\n",
        "  for plot, (key, title) in enumerate((('loss', 'risk'), ('accuracy', 'accuracy'))):\n",
        "    plt.subplot(1, 2, plot + 1)\n",
        "    plt.plot(h.history[key], label='training')\n",
        "    plt.plot(h.history['val_' + key], label='validation')\n",
        "    plt.xticks(range(0, len(h.history[key]), 10))\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel(title)\n",
        "    plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8-c98rO_rGH3",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "Based on these plots, do you think that it will be beneficial to train the classifier longer? Explain briefly.\n",
        "\n",
        "**Note:** This is a somewhat subjective judgement call, and conclusions may vary. Make sure you explain your reasoning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CNoJlABd2ngV",
        "tags": [
          "ST"
        ]
      },
      "source": [
        "### Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UxdW8dV4uoCq",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "### Problem 3.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A97WOgV8uweq",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "Suggest at least three different ways to improve the performance of the classifier defined in this Part. This could include using the data differently, modifying the network, changing how the network is trained, using multiple networks, ...\n",
        "\n",
        "For each way, explain why that would help. This is an open-ended question, and answers may vary. Do _not_ implement your suggestions, and do _not_ refer to techniques we have not covered in class.\n",
        "\n",
        "If you suggest more than three ways, we will grade you for the three best ones. However, we _will_ deduct points for patently wrong statements in any of your suggestions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "12XxnmJwnYzN",
        "tags": [
          "ST"
        ]
      },
      "source": [
        "### Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aS7fzZT9LjRW",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "### Problem 3.3 (Exam Sytle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gaC72wO3LmXv",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "The data set in the experiment above is all the data that is available, and the experiment is to be used in a conference paper that extols the virtues of the proposed neural network architecture.\n",
        "\n",
        "The data set was split into 50,000 training and 10,000 validation images. What is the most important reason why this split is not ideal?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "az3rHB_1L3Jz",
        "tags": [
          "ST"
        ]
      },
      "source": [
        "### Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wgP1spYN0Ovh",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "### Problem 3.4 (Exam Style)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dDRa1BwU0WGo",
        "tags": [
          "AST"
        ]
      },
      "source": [
        "Is it always advisable to use the model obtained at the end of the last epoch of training as the classifier for deployment? Explain briefly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I2u0xfLM0wSC",
        "tags": [
          "ST"
        ]
      },
      "source": [
        "### Answer"
      ]
    }
  ]
}